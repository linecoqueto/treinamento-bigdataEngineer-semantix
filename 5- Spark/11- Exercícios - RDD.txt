-----------------------------------------------
-- Exercícios - RDD
-----------------------------------------------
-----------------------------------------------
1. Ler com RDD os arquivos localmente do diretório “/opt/spark/logs/” ("file:///opt/spark/logs/")
-----------------------------------------------

---verificar o que tem dentro de um diretorio
!ls /opt/spark/logs

!cat /opt/spark/logs/spark--org.apache.spark.deploy--org.apache.spark

log = sc.textFile("file:///opt/spark/logs/")

-----------------------------------------------
2. Com uso de RDD faça as seguintes operações
-----------------------------------------------
a) Contar a quantidade de linhas
-----------------------------------------------

log.count()

-----------------------------------------------
b) Visualizar a primeira linha
-----------------------------------------------

log.first()

-----------------------------------------------
c) Visualizar todas as linhas
-----------------------------------------------

log.collect()

-----------------------------------------------
d) Contar a quantidade de palavras
-----------------------------------------------

#1- separar as palavras da linha
palavras = log.flatMap(lambda linha: linha.split(" "))
palavra.count()

-----------------------------------------------
e) Converter todas as palavras em minúsculas
-----------------------------------------------

minuscula = palavra.map(lambda palavra: palavra.lower())

-----------------------------------------------
f) Remover as palavras de tamanho menor que 2
-----------------------------------------------

minuscula_maior2 = minuscula.filter(lambda palavra: len(palavra) > 2)
minuscula_maior2.count()

-----------------------------------------------
g) Atribuir o valor de 1 para cada palavra
-----------------------------------------------

palavra_1 = minuscula_maior2.map(lambda palavra: (palavra,1))
palavra_1.first()

-----------------------------------------------
h) Contar as palavras com o mesmo nome
-----------------------------------------------

#2- juntar as palavras
palavra_reduce = palavra_1.reduceByKey(lambda chave1, chave2 : chave1 + chave2)
palavra_reduce.first()

-----------------------------------------------
i) Visualizar em ordem alfabética
-----------------------------------------------

palavra_ordena = palavra_reduce.sortBy(lambda palavra: palavra[0])

-----------------------------------------------
j) Visualizar em ordem decrescente a quantidade de palavras
-----------------------------------------------

palavra_ordena_qtd = palavra_reduce.sortBy(lambda palavra: palavra[1], False)

-----------------------------------------------
k) Remover as palavras, com a quantidade de palavras > 1
-----------------------------------------------

palavra_ordena_filtro = palavra_ordena_qtd.filter(lambda palavra: palavra[1]>1)

-----------------------------------------------
l) Salvar o RDD no diretorio do HDFS /user/<seu-nome>/logs_count_word
-----------------------------------------------

palavra_ordena_filtro.saveAsTextFile("/user/aline/logs_count_word")