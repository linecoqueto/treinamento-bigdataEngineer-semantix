-----------------------------------------------
UDF
-----------------------------------------------

--> User defined Function para Spark SQL

	- Registrar função como UDF
	- Comando:
		spark.udf.register(“<nomeUDF>”, <UserDefinedFunction>)

scala> val quadrado = ((s: Long) => s * s) 

python> quadrado = (lambda s: s * s)

spark.udf.register(“fQuad", quadrado)
spark.range(1, 20).registerTempTable("test")
spark.sql("select id, fQuad(id) as id_quad from test")

--> User defined Function para DataFrames
	
	- Comandos:
		<nomeUDF> = udf(<UserDefinedFunction>)
---
scala>
import org.apache.spark.sql.functions.{col, udf}
scala> val fDfQuad = udf((s: Long) => s * s)
---
python>
from pyspark.sql.functions import col,udf

def quadrado (s):
return s * s
fDfQuad = udf(lambda s: quadrado(s))
---
spark.range(1, 20).select(col(“id”), fDfQuad(col("id")))
---

-----------------------------------------------
Realmente é necessário criar?
-----------------------------------------------

	- Otimização
	- Desempenho
	- Documentação
	  . https://spark.apache.org/docs/latest/api/sql/
	  
A UDF tem um impacto forte na performance, tenha certeza ao utilizá-la.

