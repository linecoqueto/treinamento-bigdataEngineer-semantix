-----------------------------------------------
-- RDD :: Partições
-----------------------------------------------

---> spark armazena os dados do RDD em diferentes partições
---> minimo de partições é 2
---> definir partições manualmente na leitura e redução do dado

rdd.sc.textFile("entrada*",6)
palavras = rdd.flatMap(lambda linha: linha.split(" ",3)) #ERRO
p_chave_valor = palavras.map(lambda palavra : (palavra,1),20) #ERRO
p_reduce = p_chave_valor.reduceByKey(lambda key1, key2: key1 + key2, 10)
p_reduce5 = p_reduce.repartition(5)
p_reduce.getNumPartitions()